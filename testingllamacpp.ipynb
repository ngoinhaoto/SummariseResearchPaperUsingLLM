{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ritherthemuncher/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/bin/pip: line 2: /Users/ritherthemuncher/Desktop/funny ai /llamacpp/myenv/bin/python: No such file or directory\n",
      "/Users/ritherthemuncher/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/bin/pip: line 2: exec: /Users/ritherthemuncher/Desktop/funny ai /llamacpp/myenv/bin/python: cannot execute: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# !CMAKE_ARGS=\"-DLLAMA_METAL=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from llama-2-7b-chat.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:           blk.15.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.15.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:             blk.15.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.15.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:        blk.15.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:             blk.15.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:             blk.15.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.16.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.16.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:             blk.16.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.16.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:        blk.16.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.16.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:             blk.16.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:           blk.17.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.17.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.17.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:             blk.17.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:        blk.17.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.17.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:             blk.17.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:           blk.18.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.18.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.18.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.18.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:        blk.18.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.18.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.18.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.19.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.19.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.19.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.19.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.19.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:             blk.19.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.19.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.2.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.2.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:              blk.2.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.2.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:         blk.2.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.2.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:              blk.2.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.20.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.20.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.20.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.20.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.20.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.20.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.20.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.21.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.21.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.21.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.21.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.21.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.21.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.21.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.22.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.22.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.22.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.22.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.22.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.22.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.22.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.23.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.23.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.23.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.23.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.23.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.23.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.23.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:            blk.3.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:            blk.3.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:              blk.3.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:              blk.3.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:         blk.3.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:              blk.3.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:              blk.3.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:            blk.4.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:            blk.4.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:              blk.4.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:              blk.4.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:         blk.4.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:              blk.4.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:              blk.4.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:            blk.5.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:            blk.5.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:              blk.5.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:              blk.5.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:         blk.5.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:              blk.5.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:              blk.5.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:            blk.6.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:            blk.6.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:              blk.6.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:              blk.6.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:         blk.6.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:              blk.6.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:              blk.6.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:            blk.7.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:            blk.7.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:              blk.7.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:              blk.7.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:         blk.7.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:              blk.7.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:              blk.7.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:            blk.8.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:            blk.8.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:              blk.8.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:              blk.8.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:         blk.8.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:              blk.8.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:              blk.8.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:            blk.9.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:            blk.9.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:              blk.9.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:              blk.9.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:         blk.9.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:              blk.9.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:              blk.9.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.24.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:        blk.24.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:           blk.25.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:        blk.25.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:           blk.26.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:        blk.26.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.26.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.27.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:        blk.27.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.27.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:           blk.28.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:        blk.28.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.28.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:           blk.29.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:        blk.29.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.29.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:           blk.30.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.30.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:        blk.30.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.30.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 4.45 GiB (5.68 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: mem required  = 4560.97 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/ritherthemuncher/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7 (1007)\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "llama_new_context_with_model: compute buffer total size = 315.07 MiB\n",
      "llama_new_context_with_model: max tensor size =   102.54 MiB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  4561.58 MiB, (10460.95 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  1024.03 MiB, (11484.98 / 10922.67)ggml_metal_add_buffer: warning: current allocated size is greater than the recommended max working set size\n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   312.02 MiB, (11797.00 / 10922.67)ggml_metal_add_buffer: warning: current allocated size is greater than the recommended max working set size\n"
     ]
    }
   ],
   "source": [
    "n_gpu_layers = 130  # Metal set to 1 is enough.\n",
    "n_batch = 1024  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"llama-2-7b-chat.Q5_K_M.gguf\",\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    n_ctx=2048,\n",
    "    # n_ctx=512,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=False,  # Verbose is required to pass to the callback manager\n",
    ")\n",
    "llm.client.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A tiger shark (Galeocerdo cuvier) is a large, powerful predator that inhabits tropical and subtropical waters around the world. It is one of the most feared sharks in the ocean due to its aggressive behavior and reputation for attacking humans. The tiger shark can grow up to 20 feet (6 meters) long and weigh over 1,000 pounds (450 kilograms). Its distinctive stripes are thought to help it blend in with the sunlight reflecting off the water's surface, making it more difficult for prey to spot. Despite its fearsome reputation, tiger sharks play a crucial role in maintaining the balance of their ecosystems by controlling the populations of other fish and marine mammals."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nA tiger shark (Galeocerdo cuvier) is a large, powerful predator that inhabits tropical and subtropical waters around the world. It is one of the most feared sharks in the ocean due to its aggressive behavior and reputation for attacking humans. The tiger shark can grow up to 20 feet (6 meters) long and weigh over 1,000 pounds (450 kilograms). Its distinctive stripes are thought to help it blend in with the sunlight reflecting off the water's surface, making it more difficult for prey to spot. Despite its fearsome reputation, tiger sharks play a crucial role in maintaining the balance of their ecosystems by controlling the populations of other fish and marine mammals.\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Question: What is a tiger shark?\n",
    "\"\"\"\n",
    "llm(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ritherthemuncher/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/bin/pip: line 2: /Users/ritherthemuncher/Desktop/funny ai /llamacpp/myenv/bin/python: No such file or directory\n",
      "/Users/ritherthemuncher/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/bin/pip: line 2: exec: /Users/ritherthemuncher/Desktop/funny ai /llamacpp/myenv/bin/python: cannot execute: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ritherthemuncher/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/bin/pip: line 2: /Users/ritherthemuncher/Desktop/funny ai /llamacpp/myenv/bin/python: No such file or directory\n",
      "/Users/ritherthemuncher/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/bin/pip: line 2: exec: /Users/ritherthemuncher/Desktop/funny ai /llamacpp/myenv/bin/python: cannot execute: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_pdfs_from_folder(pdfs_folder):\n",
    "  summaries = []\n",
    "\n",
    "  for pdf_file in glob.glob(pdfs_folder + \"/*.pdf\"):\n",
    "    loader = PyPDFLoader(pdf_file) #load with pdfloader\n",
    "    #set up indexing by loading and splitting into chunks\n",
    "    docs = loader.load_and_split()\n",
    "    chain = load_summarize_chain(llm, chain_type='map_reduce')\n",
    "    summary = chain.run(docs)\n",
    "    # print('Summary for: ', pdf_file)\n",
    "    # print(summary)\n",
    "    # print(\"\\n\")\n",
    "    summaries.append(summary)\n",
    "  return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This publicaiton, titled \"ROLDEF: Robust Layerd Defense for Intrusion Detection Against Adversarial Attacks,\" is a conference paper written by three authors from University of California, San Diego and San Diego State University. The publication discusses the issue of adversarial attacks on intrusion detection systems and proposes a robust layered defense approach called ROLDEF to mitigate these threats. The authors have requested enhancements to the downloaded file. The paper proposes RObust Layered DEFense (ROLDEF), a defense mechanism against adversarial attacks for Machine Learning (ML)-based Intrusion Detection Systems (IDS) in Industrial Internet of Things (IIoT). ROLDEF consists of a pretrained denoising autoencoder (DAE) to detect if the input data belongs to an adversarial attack. If an attack is detected, the DAE eliminates the adversarial component and provides the purified"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m summaries \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_pdfs_from_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpdfs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[120], line 9\u001b[0m, in \u001b[0;36msummarize_pdfs_from_folder\u001b[0;34m(pdfs_folder)\u001b[0m\n\u001b[1;32m      7\u001b[0m docs \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_and_split()\n\u001b[1;32m      8\u001b[0m chain \u001b[38;5;241m=\u001b[39m load_summarize_chain(llm, chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap_reduce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print('Summary for: ', pdf_file)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(summary)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(\"\\n\")\u001b[39;00m\n\u001b[1;32m     13\u001b[0m summaries\u001b[38;5;241m.\u001b[39mappend(summary)\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain/chains/base.py:507\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    508\u001b[0m         _output_key\n\u001b[1;32m    509\u001b[0m     ]\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    513\u001b[0m         _output_key\n\u001b[1;32m    514\u001b[0m     ]\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain/chains/base.py:312\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    313\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    314\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    315\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    316\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain/chains/base.py:306\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    299\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    300\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    301\u001b[0m     inputs,\n\u001b[1;32m    302\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    303\u001b[0m )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 306\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:123\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    122\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 123\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain/chains/combine_documents/map_reduce.py:225\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_docs\u001b[39m(\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    215\u001b[0m     docs: List[Document],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    219\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# FYI - this is parallelized and so it is fast.\u001b[39;49;00m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     question_result_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39moutput_key\n\u001b[1;32m    231\u001b[0m     result_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    232\u001b[0m         Document(page_content\u001b[38;5;241m=\u001b[39mr[question_result_key], metadata\u001b[38;5;241m=\u001b[39mdocs[i]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;66;03m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(map_results)\n\u001b[1;32m    235\u001b[0m     ]\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain/chains/llm.py:227\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    226\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    228\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)\n\u001b[1;32m    229\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs})\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain/chains/llm.py:224\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    219\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    220\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    221\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_list},\n\u001b[1;32m    222\u001b[0m )\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    226\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain/chains/llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:516\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    515\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:666\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    652\u001b[0m         )\n\u001b[1;32m    653\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    654\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    655\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m         )\n\u001b[1;32m    665\u001b[0m     ]\n\u001b[0;32m--> 666\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:553\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    552\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    554\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:540\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    532\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    537\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 540\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    544\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    548\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    549\u001b[0m         )\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:1069\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1066\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1068\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1069\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[1;32m   1073\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:291\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 291\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombined_text_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:344\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    343\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 344\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/llama_cpp/llama.py:1468\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1466\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1467\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1468\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_token_eos\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/llama_cpp/llama.py:1243\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     grammar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m   1245\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m   1246\u001b[0m         top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1258\u001b[0m         grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[1;32m   1259\u001b[0m     )\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stopping_criteria \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m stopping_criteria(\n\u001b[1;32m   1261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_ids, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scores[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m   1262\u001b[0m     ):\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/llama_cpp/llama.py:1064\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m   1060\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m   1062\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m   1063\u001b[0m )\n\u001b[0;32m-> 1064\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/llama_cpp/llama.py:470\u001b[0m, in \u001b[0;36m_LlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/funny ai /SummariseResearchPaperUsingLLM/myenv/lib/python3.11/site-packages/llama_cpp/llama_cpp.py:1472\u001b[0m, in \u001b[0;36mllama_decode\u001b[0;34m(ctx, batch)\u001b[0m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllama_decode\u001b[39m(ctx: llama_context_p, batch: llama_batch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Positive return values does not mean a fatal error, but rather a warning.\u001b[39;00m\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;124;03m    0 - success\u001b[39;00m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;124;03m    1 - could not find a KV slot for the batch (try reducing the size of the batch or increase the context)\u001b[39;00m\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;124;03m    < 0 - error\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summaries = summarize_pdfs_from_folder(\"pdfs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query pdf\n",
    "\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.embeddings import LlamaCppEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in ./myenv/lib/python3.11/site-packages (0.4.19)\n",
      "Requirement already satisfied: requests>=2.28 in ./myenv/lib/python3.11/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./myenv/lib/python3.11/site-packages (from chromadb) (2.5.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in ./myenv/lib/python3.11/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in ./myenv/lib/python3.11/site-packages (from chromadb) (0.105.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in ./myenv/lib/python3.11/site-packages (from chromadb) (0.24.0.post1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./myenv/lib/python3.11/site-packages (from chromadb) (1.26.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./myenv/lib/python3.11/site-packages (from chromadb) (1.16.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./myenv/lib/python3.11/site-packages (from chromadb) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./myenv/lib/python3.11/site-packages (from chromadb) (0.15.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./myenv/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./myenv/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in ./myenv/lib/python3.11/site-packages (from chromadb) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (1.60.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./myenv/lib/python3.11/site-packages (from chromadb) (4.1.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (28.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./myenv/lib/python3.11/site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in ./myenv/lib/python3.11/site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./myenv/lib/python3.11/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in ./myenv/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in ./myenv/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in ./myenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.9.0 in ./myenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./myenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./myenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.25.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./myenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./myenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./myenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3<2.0,>=1.24.2 in ./myenv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
      "Requirement already satisfied: coloredlogs in ./myenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./myenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n",
      "Requirement already satisfied: protobuf in ./myenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.1)\n",
      "Requirement already satisfied: sympy in ./myenv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./myenv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./myenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.21.0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.42b0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.42b0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.42b0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.5.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./myenv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./myenv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./myenv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in ./myenv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.6)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in ./myenv/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.19.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./myenv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in ./myenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in ./myenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./myenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./myenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./myenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./myenv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./myenv/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./myenv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./myenv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./myenv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./myenv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in ./myenv/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./myenv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./myenv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./myenv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in ./myenv/lib/python3.11/site-packages (0.11.2)\n",
      "Requirement already satisfied: chardet in ./myenv/lib/python3.11/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in ./myenv/lib/python3.11/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in ./myenv/lib/python3.11/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in ./myenv/lib/python3.11/site-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: nltk in ./myenv/lib/python3.11/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in ./myenv/lib/python3.11/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.11/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./myenv/lib/python3.11/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: emoji in ./myenv/lib/python3.11/site-packages (from unstructured) (2.9.0)\n",
      "Requirement already satisfied: dataclasses-json in ./myenv/lib/python3.11/site-packages (from unstructured) (0.6.3)\n",
      "Requirement already satisfied: python-iso639 in ./myenv/lib/python3.11/site-packages (from unstructured) (2023.12.11)\n",
      "Requirement already satisfied: langdetect in ./myenv/lib/python3.11/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.11/site-packages (from unstructured) (1.26.2)\n",
      "Requirement already satisfied: rapidfuzz in ./myenv/lib/python3.11/site-packages (from unstructured) (3.5.2)\n",
      "Requirement already satisfied: backoff in ./myenv/lib/python3.11/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in ./myenv/lib/python3.11/site-packages (from unstructured) (4.9.0)\n",
      "Requirement already satisfied: wrapt in ./myenv/lib/python3.11/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./myenv/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./myenv/lib/python3.11/site-packages (from dataclasses-json->unstructured) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./myenv/lib/python3.11/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in ./myenv/lib/python3.11/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in ./myenv/lib/python3.11/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./myenv/lib/python3.11/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./myenv/lib/python3.11/site-packages (from nltk->unstructured) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.11/site-packages (from nltk->unstructured) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.11/site-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.11/site-packages (from requests->unstructured) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.11/site-packages (from requests->unstructured) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.11/site-packages (from requests->unstructured) (2023.11.17)\n",
      "Requirement already satisfied: packaging>=17.0 in ./myenv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./myenv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in ./myenv/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (4.36.0)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (1.26.2)\n",
      "Requirement already satisfied: scikit-learn in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./myenv/lib/python3.11/site-packages (from sentence_transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./myenv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./myenv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: sympy in ./myenv/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./myenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./myenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./myenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
      "Requirement already satisfied: click in ./myenv/lib/python3.11/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./myenv/lib/python3.11/site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./myenv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./myenv/lib/python3.11/site-packages (from torchvision->sentence_transformers) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./myenv/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in ./myenv/lib/python3.11/site-packages (0.19.4)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.11/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./myenv/lib/python3.11/site-packages (from huggingface_hub) (2023.12.2)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./myenv/lib/python3.11/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv/lib/python3.11/site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./myenv/lib/python3.11/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.11/site-packages (from requests->huggingface_hub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in ./myenv/lib/python3.11/site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in ./myenv/lib/python3.11/site-packages (from pinecone-client) (6.0.1)\n",
      "Collecting loguru>=0.5.0 (from pinecone-client)\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in ./myenv/lib/python3.11/site-packages (from pinecone-client) (4.9.0)\n",
      "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in ./myenv/lib/python3.11/site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in ./myenv/lib/python3.11/site-packages (from pinecone-client) (1.26.18)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in ./myenv/lib/python3.11/site-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./myenv/lib/python3.11/site-packages (from pinecone-client) (1.26.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.11/site-packages (from requests>=2.19.0->pinecone-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.11/site-packages (from requests>=2.19.0->pinecone-client) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.11/site-packages (from requests>=2.19.0->pinecone-client) (2023.11.17)\n",
      "Installing collected packages: loguru, dnspython, pinecone-client\n",
      "Successfully installed dnspython-2.4.2 loguru-0.7.2 pinecone-client-2.2.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import pinecone\n",
    "import os\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader('pdfs') #we load an entire folder\n",
    "data = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/375594560\\nROLDEF: Robust La yered Defense for Intrusion Detection Against Adversarial\\nAttacks\\nConf erence Paper  · Mar ch 2024\\nCITATIONS\\n0READS\\n62\\n3 author s, including:\\nOnat Gung or\\nUniv ersity of Calif ornia, San Die go\\n18 PUBLICA TIONS \\xa0\\xa0\\xa097 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nBaris Aksanli\\nSan Die go St ate Univ ersity\\n83 PUBLICA TIONS \\xa0\\xa0\\xa01,138  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Onat Gung or on 12 No vember 2023.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.', metadata={'source': 'pdfs/ROLDEF_DATE24.pdf', 'page': 0}),\n",
       " Document(page_content='ROLDEF: RObust Layered DEFense for Intrusion\\nDetection Against Adversarial Attacks\\nOnat Gungor1,2, Tajana Rosing1, and Baris Aksanli2\\n1Department of Electrical and Computer Engineering, University of California, San Diego\\n2Department of Electrical and Computer Engineering, San Diego State University\\nogungor@ucsd.edu, tajana@ucsd.edu, baksanli@sdsu.edu\\nAbstract —The Industrial Internet of Things (IIoT) includes\\nnetworking equipment and smart devices to collect and analyze\\ndata from industrial operations. However, IIoT security is chal-\\nlenging due to its increased inter-connectivity and large attack\\nsurface. Machine learning (ML)-based intrusion detection system\\n(IDS) is an IIoT security measure that aims to detect and respond\\nto malicious traffic by using ML models. However, these methods\\nare susceptible to adversarial attacks. In this paper, we propose a\\nRObust Layered DEFense ( ROLDEF ) against adversarial attacks.\\nOur denoising autoencoder (DAE) based defense approach first\\ndetects if a sample comes from an adversarial attack. If an\\nattack is detected, adversarial component is eliminated using the\\nmost effective DAE and the purified data is provided to the ML\\nmodel. We use a realistic IIoT intrusion data set to validate the\\neffectiveness of our defense across various ML models, where\\nwe improve the average prediction performance by 114% with\\nrespect to no defense. Our defense also provides 50% average\\nprediction performance improvement compared to the state-of-\\nthe-art defense under various adversarial attacks. Our defense\\ncan also be deployed for any underlying ML model and provides\\nan effective protection against adversarial attacks.\\nI. I NTRODUCTION\\nThe Industrial Internet of Things (IIoT) is the connection of\\nindustrial assets with the information systems and the business\\nprocesses [1]. It continuously monitors and analyzes collected\\ndata towards better system efficiency and reliability. Its value\\nincreases where IIoT could be worth $7.1 trillion in the United\\nStates by 2030 [2]. Increased inter-connectivity and poorly\\nimplemented security features make IIoT an easy target for\\ncybercriminals [3]. An adversary can exploit vulnerabilities\\nto modify system data, disrupt communication, or prevent\\nasset availability [4]. Recent cyberattacks include StuxNet\\nand Industroyer [3]. IIoT security is challenging due to long\\nlifetime of industrial devices and increased interconnection\\namong IIoT devices [5]. Intrusion Detection System (IDS) is a\\nsecurity solution that continuously monitors the network data\\nto detect cyberattacks [6]. Machine learning (ML) methods\\nhave been recently adopted for IDS due to their accuracy [7].\\nAlthough ML methods provide good intrusion detection\\nperformance, they can be vulnerable to small changes in the\\ninput data. In an adversarial attack, an adversary creates slight\\nbut carefully-crafted examples to affect the ML prediction\\nperformance [4]. Fig. 1 demonstrates the impact of an ad-\\nversarial attack (under varying perturbation amounts) on ML\\nprediction performance for intrusion detection. Here, 0% per-\\n(a)Accuracy\\n (b)F1Score\\nFig. 1: ML prediction performance under adversarial attack\\nturbation refers to no adversarial attack. Higher perturbation\\namount implies a stronger adversarial attack. In this figure,\\ndifferent colors denote select ML methods, e.g., random forest\\n(RF), hyperdimensional computing (HD), deep neural network\\n(DNN). Under an adversarial attack, accuracy (Fig. 1a) and\\nF1score (Fig. 1b) can be impacted significantly irrespective\\nof the underlying ML model, causing up to 25 ×performance\\nloss. These results motivate the need for an effective defensive\\nmechanism against adversarial attacks for ML-based IDS.\\nIn this work, we propose RObust Layered DEFense\\n(ROLDEF ) which is presented in Fig. 2. Given test data, we\\nfirst use a pretrained denoising autoencoder (DAE) to predict\\nthe perturbation amount. We then mark if the data belongs\\nto an adversarial attack depending on the perturbation amount\\nprediction. If the input is predicted to be an attack, we perform\\nDAE selection where the best performing DAE is chosen. The\\nselected DAE eliminates the perturbation and passes the data\\nto the pretrained ML algorithm. Comprehensive experiments\\non a realistic IIoT intrusion detection dataset [8] show that\\nROLDEF provides both robust and effective defense for var-\\nious ML methods under different adversarial attacks. It can\\nimprove average model prediction performance by 114% with\\nrespect to no defense. ROLDEF is also consistently better\\nthan the state-of-the-art (SoA) adversarial training defense\\n[9] with 50.1% average prediction performance improvement.\\nWhile improving adversarial robustness, our defense requires\\nadditional 0.09 milliseconds per sample (on average) com-\\npared to the SoA defense. Most importantly, ROLDEF can be\\ndeployed for any ML-based IDS and could effectively protect\\nthe learning system against adversarial attacks.', metadata={'source': 'pdfs/ROLDEF_DATE24.pdf', 'page': 1}),\n",
       " Document(page_content='Fig. 2: Proposed defense framework ( ROLDEF )\\nII. R ELATED WORK\\nA. IIoT Security\\nIIoT is an adaptation of traditional IoT for industrial en-\\nvironments enabling full automation, remote monitoring, and\\npredictive maintenance [10]. Due to inadequate standardization\\nand the lack of required skills to implement them, IIoT has\\nbecome a target for different cyber attacks, e.g., denial of\\nservice, eavesdropping, man-in-the-middle, spoofing, and side\\nchannel [11]. An adversary can gain access to an entire IIoT\\nsystem by exploiting its vulnerable assets such as operating\\nsystems, application software, industrial communication pro-\\ntocols, and smart devices [12]. There are advanced security\\nsolutions in traditional IT systems, yet these cannot be directly\\nused in IIoT systems due to IIoT’s limited power, constrained\\nfunctionality, and lightweight network protocols. ML-based\\nIDS is one possible security solution that trains ML models by\\nusing historical network data to detect attacks and anomalies\\n[6]. There are different models proposed in the literature, e.g.,\\nlogistic regression, random forest, deep neural networks [7].\\nB. Adversarial Attacks and Defenses\\nAdversarial attacks craft perturbed input data to fool ML\\nmodels [4]. These attacks can significantly impact ML-based\\nIDS decisions where benign data can be classified as an attack\\nor vice versa. To effectively generate those instances, attacker\\ncan use white-box or black-box attacks [13]. While white-box\\nexploits complete knowledge of an ML model, i.e., model pa-\\nrameters and architecture, black-box refines adversarial input\\nbased on an output generated from the model. Adversarial\\ndefenses aim to protect ML models against adversarial attacks\\nunder three main groups [14]: (i) input defense, (ii) adversarial\\nattack detection, and (iii) model defense. Input defense pre-\\nprocesses input data to remove any adversarial component,\\ne.g., data compression, data coding, data decomposition. Ad-\\nversarial attack detection aims to distinguish adversarial attack\\ndata from clean ones before model training and inference,\\ne.g., data feature analysis, ML-based detection. Model de-\\nfense strengthens the ML model against adversarial attacks\\nvia further modifications, e.g., gradient masking, defensive\\ndistillation, adversarial training.\\nFig. 3: Adversarial Transfer Attack Framework\\nC. Denoising Autoencoder (DAE) Defense\\nAutoencoder (AE) is an unsupervised learning setting which\\nconsists of encoder, code, and decoder. Encoder performs\\ninput compression and generates the code, and the decoder\\nreconstructs the input from the code [15]. The AE goal is to\\nget an output identical with the input. However, AE carries a\\nrisk of learning identity function where input is directly copied\\nto the output without any learning performed. Denoising AE\\n(DAE) solves this problem through noise injection. DAE first\\nadds some random noise to the input data and reconstructs the\\nclean data. Due to this property, DAE is capable of removing\\nadversarial noise before target model prediction. Hence, DAE\\ncan be used as a defense against adversarial attacks where per-\\nturbed data is pre-processed before model prediction. There are\\nseveral AE-based defenses in the literature: MagNet [16], deep\\ndenoising sparse autoencoder (DDSA) [17], adversarial noise\\nremoving network (ARN) [18], and adversarial purification\\ndenoising autoencoder (APuDAE) [19]. All these defenses are\\napplied to images, and do not apply to the time series data.\\nIII. ROLDEF FRAMEWORK\\nFig. 2 illustrates our RObust Layered DEFense framework\\nROLDEF . Our defense is based on denoising autoencoder\\n(DAE) to remove adversarial perturbation before ML model\\ninference. We use DAE since it can purify noisy samples by\\nreconstructing the output that is like the clean input [19]. Given\\ntest data with a window size ω, the first step is to determine\\nthe perturbation prediction amount ˆδ. Perturbation prediction ˆδ\\nis calculated by finding the average difference between DAE\\ninput and reconstructed output. We then compare ˆδwith a\\npredefined threshold level Tto mark it as clean or attack data.\\nIf an attack is detected ( ˆδ > T ), we select the best performing\\nDAE (against adversarial attacks) among a set of pretrained\\nDAEs. Finally, data is purified and given to the ML model\\nto obtain the prediction metrics, e.g., F1score, accuracy. We\\nuse 6 ML methods: decision tree (DT), random forest (RF),\\nlogistic regression (LR), naive bayes (NB), hyperdimensional\\ncomputing (HD) [20], and deep neural network (DNN). How-\\never, ROLDEF can work with any ML-based IDS system,\\nmaking it a generalizable defense solution.\\nA. Black-box Transfer Attack Framework\\nFig. 3 presents our black-box transfer attack framework.\\nBlack-box attacks represent a more realistic attack scenario', metadata={'source': 'pdfs/ROLDEF_DATE24.pdf', 'page': 2}),\n",
       " Document(page_content='Fig. 4: Adversarial attack simulation\\nwhere the attacker can be an outsider, with limited knowledge\\nabout the internal system [21]. Adversary first needs to create\\na surrogate (substitute) model and access the validation data to\\ncreate adversarial examples. Attackers usually exploit network\\nvulnerabilities to access data in IIoT systems. We select 4\\ndifferent gradient-based attacks: fast gradient sign method\\n(FGSM) [22], randomized fast gradient sign method (RFGSM)\\n[23], projected gradient descent (PGD) [9], and momentum\\niterative method (MIM) [24]. We select these attacks since\\nthey are the most common attacks in time-series classification\\n[25]. We use a deep neural network (DNN) as the surrogate\\nmodel due to its superior prediction performance [8]. We train\\nit using the training data. The attacker then uses the validation\\ndata to create attacks and send them to the target ML models.\\nThe selected target ML models are DT, RF, LR, NB, HD,\\nand DNN. We use a separate target DNN model to make the\\nattack black-box, i.e., the surrogate and target ML models are\\ndifferent. These methods are selected due to their prevalence in\\nthe IDS domain [26]. All these methods are previously trained\\nusing our training data. Given perturbed validation data, we\\nstore the prediction performance for each attack type and ML\\nmodel to keep track of the individual attack effectiveness.\\nBased on these values, we select the most effective DAE\\nadversarial noise type as provided in Section III-E.\\nB. Denoising Autoencoder (DAE) Training\\nWe perform two main modifications to the traditional DAE\\ntraining: (i) injecting adversarial noise and (ii) including clean\\ndata. For the former, we use the adversarial attack data instead\\nof some random noise such as Gaussian noise. To create\\nthe adversarial attack data, we leverage the black-box attack\\nframework in Fig. 3 and input it to the DAE. For the latter\\nchange, we also incorporate some clean data into the training\\nto increase DAE robustness in case there is no adversarial\\nattack. Our experiments showed that both changes contributed\\nto the DAE adversarial robustness positively since DAE is able\\nto learn the reconstruction of adversarial examples with some\\nclean data. This means that when trained DAE receives some\\nattack and clean data, it reconstructs the data more accurately.\\nOverall, we train four different DAEs corresponding to differ-\\nent adversarial attacks. We give equal weights to the clean and\\nattack data in training, i.e., 50% clean, 50% attack data due\\nto more accurate predictions under adversarial attacks among\\ndifferent ratios. As the output of DAE training, we obtain\\nfour trained DAEs which are going to be used in perturbation\\nprediction and perturbation removal.\\nFig. 5: DAE performance under varying adversarial attacks\\n(ξ= 20 ,ADR = 50% )\\nC. Variation in Adversarial Attacks\\nAdversarial attacks can change in time where an adversary\\ncan try different attacks to deceive the deployed ML method\\n[27]. To reflect this situation, we receive the test data in\\nwindows, with size ω. We shift each window by ωat each\\niteration and receive the new set of data continuously (or\\nuntil all test data is consumed). Here, we assume that data\\nis processed in windows, i.e., data is fed into the target\\nML model after all data from a window is received. Fig. 4\\nsimulates an adversarial attack scenario where clean (green\\nsquare) or attack data (red, yellow, and orange squares) is\\nreceived during each time window, e.g., ω1, ω2. Each time\\nwindow consists of Mnumber of samples, i.e., s1, s2, . . . , s M.\\nWe observe that different attacks (denoted by distinct colors)\\nmight arrive at random times with random frequencies. Based\\non this observation, we consider three possible adversarial\\nattack scenarios: (i) adversary always conducts an attack, i.e.,\\nall samples are attack, (ii) adversary never conducts an attack,\\ni.e., all samples are clean, and (iii) adversary conducts an\\nattack at some random time with unknown frequencies, i.e.,\\nsome samples are attack/clean. Among these three scenarios,\\nthe last one represents the most realistic and stealthy attack\\nsetting since the adversary would not want to be detected\\nby a defense mechanism. Let ξdenote the selected number\\nof windows in a given test data. So, in a single window ω,\\nwe have N/ξ samples where Nis the total number of test\\nsamples. To denote the number of times adversarial attack\\nis conducted in total, we introduce attack data ratio ( ADR )\\nwhich is the number of attack windows ( ξattack ) divided by\\nthe total number of windows ( ξ=ξattack +ξclean ):\\nAttack data ratio ( ADR )=ξattack\\nξattack +ξclean(1)\\nWe select different ADR s to show the validity of the proposed\\ndefense, covering all three adversarial attack scenarios.\\nD. Layered Defense Motivation\\nFig. 5 presents the pretrained DAEs’ defense performance\\nagainst varying adversarial attacks where ξis 20, and ADR\\nis 50%. This figure uses HD as the target ML model. Here, a', metadata={'source': 'pdfs/ROLDEF_DATE24.pdf', 'page': 3}),\n",
       " Document(page_content='random adversarial attack is selected for the attack samples\\nand the result represents average values over all test win-\\ndows. While x-axis is the prediction metric, y-axis has the\\ncorresponding values in percentage. Different colors represent\\nDAEs trained with different adversarial attacks (e.g., MIM-\\nDAE denotes DAE with MIM noise injection) and No Defense\\nis indicated by light blue color. We observe that No Defense\\noutperforms DAE defenses based on F1score. This is due\\nto the DAE performance under clean data. Although DAE\\nperforms well under adversarial attacks, its performance gets\\nworse with clean data where traditional training is favorable.\\nThis means that defense should be adaptive based on the\\nreceived data, i.e., clean or attack. To solve this problem, we\\ndevise a layered defense mechanism based on DAE perturba-\\ntion prediction where we determine if an attack is conducted\\nand remove the perturbation if there is an adversarial attack.\\nE. Perturbation Prediction\\nPerturbation prediction calculates the amount of perturba-\\ntion in a given data. Based on the perturbation prediction ˆδ,\\nwe categorize the data as clean or attack. Given input data ¨x,\\nDAE reconstructs it to obtain x′. We calculate the perturbation\\namount ˆδby finding the absolute difference between ¨xandx′\\naveraged over all samples:\\nˆδ=PM\\ni=1abs(¨xi−x′\\ni)\\nM(2)\\nwhere abs is the absolute value function and Mis the\\nnumber of samples in a single window. To calculate the\\nperturbation amount, we use the DAE trained with the most\\neffective attack which is determined based on our attack\\nprediction performance result from Section III-A. This is\\nselected for each target ML method. After ˆδis calculated,\\nwe determine if the data is from an attack or not using a\\nthreshold level T. Ifˆδ≤T, we have clean data; otherwise\\n(ˆδ > T ) we have an attack data. In case of an adversarial\\nattack detection, we utilize our pretrained DAEs to remove\\nthe adversarial perturbation, otherwise we directly use our\\npretrained ML models without any further modification.\\nF . DAE Selection and Perturbation Removal\\nAfter we predict that the given data comes from an attack,\\nthe best DAE is selected and applied as a defense mechanism.\\nFor this selection, we denoise the perturbed data via pretrained\\nDAEs and provide it to the target model. This model then\\noutputs the performance metrics corresponding to individual\\nDAEs. Based on these metrics, we select the DAE that gives\\nthe best prediction performance. The selected DAE is then\\nused as a defense. It is important to note that the best DAE\\ncan change at each time window and for each ML method.\\nIV. E XPERIMENTAL ANALYSIS\\nA. Dataset Description\\nWe use a realistic IIoT intrusion dataset, X-IIoTID [8]. X-\\nIIoTID is a device and connectivity agnostic dataset whichaddresses the heterogeneity of IIoT network traffic and sys-\\ntems’ activities generated from distinct connectivity protocols,\\ndevices, and communication patterns. 18 different attacks are\\nincluded in the dataset: malicious insider, reverse shell, MitM\\nattack, MQTT cloud broker-subscription, generic scanning,\\nModbus-Register reading, TCP relay attack, scanning vulner-\\nabilities, fuzzing, discovering resources, brute force attack,\\ndictionary attack, command and control, exfiltration, false data\\ninjection, fake notification, crypto-ransomware, and ransom\\ndenial of service. The input data comes from end-to-end\\nnetwork traffic, physical properties, host device logs, the host\\ndevice’s resources, and alert logs. Data collection began on\\nDecember 5, 2019, ran for many hours each day, and ended\\non March 23, 2020 (not continuous). The overall learning goal\\nis to map the input data to the attack labels.\\nB. Experimental Setup\\nWe run all experiments on a PC with 16 GB RAM and\\nan 8-core 2.3 GHz Intel Core i9 processor. For our surrogate\\nmodel, we select a DNN with 2 hidden layers with 30, and 20\\nunits. To train this DNN, we use SGD optimizer with learning\\nrate 0.01, ReLU activation function, and batch size of 32. For\\nour traditional ML target models, e.g., DT, RF, we perform a\\ngrid search to find their optimal hyper-parameters. For HD, we\\nset HV dimension to 1000, used random projection encoding,\\nand set learning rate to 2 after detailed experiments. Our target\\nDNN consists of 3 hidden layers with 50, 30, and 20 units.\\nThe selected defense DAE structure contains an encoder with\\n32, 16, and 8 units and a decoder with 16, 32 and 58 units.\\nDAE is trained using Adam optimizer, with mean squared\\nerror loss. For DAE noise injection, we add noise generated\\nfrom{FGSM, RFGSM, PGD, MIM }attack set with 0.5 as\\nthe perturbation amount. We also included 50% clean and 50%\\nattack data in training which gives the best prediction perfor-\\nmance under various adversarial attacks. We set the number of\\nwindows ( ξ) to 20. This selection brings the largest prediction\\nimprovement over no defense. We report average metrics over\\nall windows. For varying adversarial attacks, we select a ran-\\ndom attack from the {FGSM, RFGSM, PGD, MIM }set with\\nthe random perturbation from the interval [ 0.1,0.9]. For ADR,\\nwe experimented with the ratios (%) from {0,25,50,100}to\\nconsider different adversarial attack scenarios. We also set the\\nthreshold level Tto 0.01 to differentiate attack samples from\\nclean ones after detailed experiments. To measure the defense\\nperformance, we select 2 metrics: accuracy and F1score. Since\\nwe have an unbalanced dataset (number of attack samples are\\nrelatively smaller than clean ones), F1score provides a more\\nmeaningful insight.\\nC. State-of-the-art Defense\\nAdversarial training (AT) [9]: AT is widely accepted as the\\nmost effective defense method against adversarial attacks [28].\\nWe selected this as the state-of-the-art defense since it can be\\napplied to any ML model. It incorporates adversarial attack\\ndata into the training process. For the DNN, we retrain the\\nmodel via adversarial attack samples where network weights', metadata={'source': 'pdfs/ROLDEF_DATE24.pdf', 'page': 4}),\n",
       " Document(page_content='(a) DT\\n (b) RF\\n(c) LR\\n (d) NB\\n(e) HD\\n (f) DNN\\nFig. 6: Accuracy Comparison Among No Defense ,SoA\\nDefense (AT) [9], and Our Defense ( ROLDEF )\\nare updated. For traditional ML methods, we retrain the\\nmodels by including adversarial attack data. For HD, class\\nhyper-vectors are updated inspired by the method presented\\nby Ma et al. [29]. For each ML method’s adversarial training,\\nwe use the best adversarial attack to obtain the most effective\\ndefense performance. Hence, we report the most effective\\nadversarial training defense in our experimental results.\\nDefensive Distillation (DD) [30]: DD is another well-\\nknown defense approach against adversarial attacks when\\nadversarial data is not allowed during training. This approach\\nuses two DNNs: initial and distilled network. Initial DNN\\nprobability vector predictions are given to the distilled network\\nand training is performed with the original labels. Trained\\ndistilled network is used as the inference model. We make\\na comparison with DD when the target model is DNN.\\nD. Experimental Results\\nROLDEF Performance: Fig. 6 and Fig. 7 compare\\nROLDEF (green color) against the SoA defense [9] (yellow\\ncolor), and No Defense (red color) in terms of accuracy and\\nF1score respectively. Each sub-figure has varying attack data\\nratio ( ADR ) on the x-axis and y-axis is accuracy or F1score.\\nIn terms of accuracy (Fig. 6), our defense consistently provides\\nthe best prediction performance across various target models\\nandADR values. Table I presents our method’s accuracy im-\\nprovement over No Defense andSoA defense . Compared to No\\nDefense ,ROLDEF brings up to 965.1% (259.4% on average)\\n(a) DT\\n (b) RF\\n(c) LR\\n (d) NB\\n(e) HD\\n (f) DNN\\nFig. 7: F1Score Comparison Among No Defense ,SoA\\nDefense (AT) [9], and Our Defense ( ROLDEF )\\nTABLE I: ROLDEF Accuracy Improvement (%)\\nNo Defense SoA Defense [9]\\nTarget Model Maximum Average Maximum Average\\nDT 144.6 45.7 11.3 6.9\\nRF 21.8 7.4 18.0 8.5\\nLR 91.4 35.0 35.1 13.7\\nNB 162.4 57.2 44.6 19.8\\nHD 67.0 25.2 26.6 24.7\\nDNN 965.1 259.4 42.7 21.7\\naccuracy improvement when the target model is DNN. With\\nrespect to SoA defense ,ROLDEF provides up to 44.6% (24.7%\\non average) accuracy improvement. Compared to No Defense\\nandSoA defense , we can obtain 71.7% and 15.9% accuracy\\nimprovement over all target models respectively.\\nIn terms of F1scores (Fig. 7), we can observe the superior-\\nity of our defense. ROLDEF is consistently the best approach\\nwhen ADR > 0. Table II shows our method’s F1score\\nimprovement over No Defense and SoA defense . Compared\\nTABLE II: ROLDEF F1Score Improvement (%)\\nNo Defense SoA Defense [9]\\nTarget Model Maximum Average Maximum Average\\nDT 219.1 59.6 13.1 6.4\\nRF 375.7 98.8 9.1 3.5\\nLR 54.4 19.4 30.9 11.8\\nNB 82.6 31.9 17.0 6.8\\nHD 112.1 36.2 34.9 29.3\\nDNN 1706.3 438.1 440.6 242.9', metadata={'source': 'pdfs/ROLDEF_DATE24.pdf', 'page': 5}),\n",
       " Document(page_content='TABLE III: Defense Comparison under DNN Target Model\\nAccuracy F1 Score\\nADR (%) / Defense AT[9] DD[30] ROLDEF AT[9] DD[30] ROLDEF\\n100 73.3 26.8 65.1 30.1 9.4 30.7\\n50 66.6 60.6 81.6 18.5 46.1 58.9\\n25 68.7 78.9 91.2 17.9 64.9 73.2\\n0 68.1 96.8 97.2 15.8 83.5 85.6\\nAverage 69.2 65.8 83.8 20.6 50.9 62.1\\ntoNo Defense ,ROLDEF brings up to 1706.3% (438.1% on\\naverage) F1score improvement. With respect to SoA defense ,\\nROLDEF provides up to 440.6% (242.9% on average) F1\\nscore improvement. We can obtain 114% and 50.1% F1score\\nimprovement over No Defense andSoA defense when all target\\nmodels are considered. Overall, we can note that our defense\\nconsistently improves the prediction performance irrespective\\nof the underlying target model.\\nDefense Comparison under DNN Target Model: Based\\non Table II, the largest improvement is observed when the\\ntarget model is DNN. This result can be attributed to the\\nsimilarity between surrogate and target models. Since the ad-\\nversarial attack data is crafted via a DNN surrogate, it can fool\\nthe target DNN the most although they have different network\\nstructures. To further demonstrate the effectiveness of our\\ndefense under DNN target model, we compare ROLDEF with\\ndefensive distillation (DD) [30]. Table III presents the results\\nof this comparison. We observe that our defense provides the\\nbest prediction performance under all ADR values, solidifying\\nthe case for the superiority of our defense.\\nOverhead Analysis: ROLDEF overhead is the sum of\\nperturbation prediction and DAE selection. Table IV shows\\nour method’s additional per sample overhead over the selected\\nADR values compared to the SoA defense . When average\\nexecution time is calculated over all target ML methods,\\nrunning our defense requires an additional 0.09 milliseconds\\nper sample compared to the SoA defense . For our data set, a\\nsample refers to the time interval between the last and the first\\npacket seen in a network traffic flow [8], where the median\\ntraffic flow duration is 4.98 ms. Compared to the median traffic\\nflow duration, our method’s overhead is around 1.8%.\\nTABLE IV: ROLDEF Overhead Analysis\\nTarget Model DT RF LR NB HD DNN\\nAdditional Overhead (ms) 0.08 0.14 0.09 0.09 0.11 0.06\\nV. C ONCLUSION\\nIndustrial Internet of Things (IIoT) security is challeng-\\ning owing to its large attack surface, and increased inter-\\nconnectivity. Intrusion Detection Systems (IDSs) dynamically\\nmonitor the behavior of an IIoT system to detect malicious\\nactivity. ML-based IDS solution is popular owing to its great\\nprediction performance. However, ML methods are sensitive\\nto adversarial attacks, impacting their prediction performance\\nsignificantly. These attacks can happen with unknown pertur-\\nbations and frequencies. Hence, defense should be adaptive\\nagainst attacks. In this paper, we proposed a robust layered\\ndefense against adversarial attacks. Our DAE-based defensefirst detects if sample comes from an attack. If attack is\\ndetected, adversarial noise is eliminated using the best DAE.\\nOur defense improved average model prediction performance\\nby 114% and 50% with respect to no defense and the state-\\nof-the-art adversarial training defense.\\nREFERENCES\\n[1] E. Sisinni et al. , “Industrial internet of things: Challenges, opportunities,\\nand directions,” IEEE transactions on industrial informatics , vol. 14,\\nno. 11, pp. 4724–4734, 2018.\\n[2] P. Daugherty and B. Berthon, “Winning with the industrial internet\\nof things: How to accelerate the journey to productivity and growth,”\\nDubl ´ın: Accenture , 2015.\\n[3] K. Tange et al. , “A systematic survey of industrial internet of things\\nsecurity: Requirements and fog computing opportunities,” IEEE Com-\\nmunications Surveys & Tutorials , vol. 22, no. 4, pp. 2489–2520, 2020.\\n[4] O. Gungor, T. Rosing, and B. Aksanli, “Stewart: Stacking ensemble\\nfor white-box adversarial attacks towards more resilient data-driven\\npredictive maintenance,” Computers in Industry , vol. 140, p. 103660,\\n2022.\\n[5] M. Serror et al. , “Challenges and opportunities in securing the industrial\\ninternet of things,” IEEE Transactions on Industrial Informatics , vol. 17,\\nno. 5, pp. 2985–2996, 2020.\\n[6] E. Anthi et al. , “Adversarial attacks on machine learning cybersecurity\\ndefences in industrial control systems,” Journal of Information Security\\nand Applications , vol. 58, p. 102717, 2021.\\n[7] H. Liu and B. Lang, “Machine learning and deep learning methods for\\nintrusion detection systems: A survey,” applied sciences , vol. 9, no. 20,\\np. 4396, 2019.\\n[8] M. Al-Hawawreh et al. , “X-iiotid: A connectivity-agnostic and device-\\nagnostic intrusion data set for industrial internet of things,” IEEE Internet\\nof Things Journal , vol. 9, no. 5, pp. 3962–3977, 2021.\\n[9] A. Madry et al. , “Towards deep learning models resistant to adversarial\\nattacks,” arXiv preprint arXiv:1706.06083 , 2017.\\n[10] O. Gungor, T. S. Rosing, and B. Aksanli, “Dowell: diversity-induced\\noptimally weighted ensemble learner for predictive maintenance of\\nindustrial internet of things devices,” IEEE Internet of Things Journal ,\\nvol. 9, no. 4, pp. 3125–3134, 2021.\\n[11] M. Lezzi, M. Lazoi, and A. Corallo, “Cybersecurity for industry 4.0 in\\nthe current literature: A reference framework,” Computers in Industry ,\\nvol. 103, pp. 97–110, 2018.\\n[12] D. Wu et al. , “Cybersecurity for digital manufacturing,” Journal of\\nmanufacturing systems , vol. 48, pp. 3–12, 2018.\\n[13] K. Warr, Strengthening deep neural networks: Making AI less susceptible\\nto adversarial trickery . O’Reilly Media, 2019.\\n[14] J. Li, Y . Liu, T. Chen, Z. Xiao, Z. Li, and J. Wang, “Adversarial attacks\\nand defenses on cyber–physical systems: A survey,” IEEE Internet of\\nThings Journal , vol. 7, no. 6, pp. 5103–5115, 2020.\\n[15] A. G ´eron, Hands-on machine learning with Scikit-Learn, Keras, and\\nTensorFlow . ” O’Reilly Media, Inc.”, 2022.\\n[16] D. Meng and H. Chen, “Magnet: a two-pronged defense against adver-\\nsarial examples,” in Proceedings of the 2017 ACM SIGSAC conference\\non computer and communications security , pp. 135–147, 2017.\\n[17] Y . Bakhti, S. A. Fezza, W. Hamidouche, and O. D ´eforges, “Ddsa:\\nA defense against adversarial attacks using deep denoising sparse\\nautoencoder,” IEEE Access , vol. 7, pp. 160397–160407, 2019.\\n[18] D. Zhou et al. , “Towards defending against adversarial examples\\nvia attack-invariant features,” in International Conference on Machine\\nLearning , pp. 12835–12845, PMLR, 2021.\\n[19] D. Kalaria et al. , “Towards adversarial purification using denoising\\nautoencoders,” arXiv preprint arXiv:2208.13838 , 2022.\\n[20] L. Ge and K. K. Parhi, “Classification using hyperdimensional comput-\\ning: A review,” IEEE Circuits and Systems Magazine , vol. 20, no. 2,\\npp. 30–47, 2020.\\n[21] S. Bhambri et al. , “A survey of black-box adversarial attacks on\\ncomputer vision models,” arXiv preprint arXiv:1912.01667 , 2019.\\n[22] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing\\nadversarial examples,” arXiv preprint arXiv:1412.6572 , 2014.\\n[23] E. Wong, L. Rice, and J. Z. Kolter, “Fast is better than free: Revisiting\\nadversarial training,” arXiv preprint arXiv:2001.03994 , 2020.\\n[24] Y . Dong et al. , “Boosting adversarial attacks with momentum,” in CVPR ,\\npp. 9185–9193, 2018.', metadata={'source': 'pdfs/ROLDEF_DATE24.pdf', 'page': 6}),\n",
       " Document(page_content='[25] H. I. Fawaz et al. , “Adversarial attacks on deep neural networks for time\\nseries classification,” in IJCNN , pp. 1–8, IEEE, 2019.\\n[26] P. Mishra et al. , “A detailed investigation and analysis of using machine\\nlearning techniques for intrusion detection,” IEEE communications sur-\\nveys & tutorials , vol. 21, no. 1, pp. 686–728, 2018.\\n[27] Y . Gong, B. Li, C. Poellabauer, and Y . Shi, “Real-time adversarial\\nattacks,” arXiv preprint arXiv:1905.13399 , 2019.\\n[28] T. Bai et al. , “Recent advances in adversarial training for adversarial\\nrobustness,” arXiv preprint arXiv:2102.01356 , 2021.\\n[29] D. Ma et al. , “Hdtest: Differential fuzz testing of brain-inspired hyper-\\ndimensional computing,” in 2021 DAC , pp. 391–396, IEEE, 2021.\\n[30] N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, “Distillation\\nas a defense to adversarial perturbations against deep neural networks,”\\ninIEEE symposium on security and privacy (SP) , pp. 582–597, 2016.\\nView publication stats', metadata={'source': 'pdfs/ROLDEF_DATE24.pdf', 'page': 7}),\n",
       " Document(page_content='JournalofMachineLearning Research 9(2008)993-996 Submitted 10/07;Revised3/08;Published 6/08\\nShark\\nChristian Igel CHRISTIAN.IGEL@NEUROINFORMATIK.RUB.DE\\nVerenaHeidrich-Meisner VERENA.HEIDRICH-MEISNER@NEUROINFORMATIK.RUB.DE\\nTobiasGlasmachers TOBIAS.GLASMACHERS@NEUROINFORMATIK.RUB.DE\\nInstitut f¨urNeur oinformatik\\nRuhr -Univer sit¨atBochum\\n44780 Bochum, Germany\\nEditor:SoerenSonnenburg\\nAbstract\\nSHARKisanobject-oriented libraryforthedesignofadaptivesystems. Itcomprises methodsfor\\nsingle-andmulti-objecti veoptimization (e.g.,evolutionary andgradient-based algorithms) aswell\\naskernel-based methods, neuralnetworks,andothermachinelearningtechniques.\\nKeywords:machinelearningsoftware,neuralnetworks,kernel-methods, evolutionary algorithms,\\noptimization, multi-objecti ve-optimization\\n1.Overview\\nSHARK isamodular C++ library forthedesign andoptimization ofadapti vesystems. Itservesas\\natoolbox forrealworldapplications andbasic research incomputational intelligence andmachine\\nlearning. Thelibrary provides methods forsingle- andmulti-objecti veoptimization, inparticular\\nevolutionary andgradient-based algorithms, kernel-based learning methods, neural netw orks, and\\nmanyother machine learning techniques. Itsmain design criteria areﬂexibility andspeed. Here\\nwerestrict thedescription ofSHARK toitscore components, albeit thelibrary contains plenty of\\nadditional functionality. Further information canbeobtained from theHTML documentation and\\ntutorials. More than 60illustrati veexample programs serveasstarting points forusing SHARK .\\n2.Basic Tools—Rng, Array ,andLinAlg\\nThelibrary provides general auxiliary functions anddata structures forthedevelopment ofmachine\\nlearning algorithms. The Rng module generates reproducible andplatform independent sequences\\nofpseudo random numbers, which canbedrawnfrom 14predeﬁned discrete andcontinuous para-\\nmetric distrib utions. The Arrayclass provides dynamical array templates ofarbitrary type anddi-\\nmension aswell asbasic operations acting onthese templates. LinAlg implements linear algebra\\nalgorithms such asmatrix inversion andsingular value decomposition.\\n3.ReClaM—Regr ession andClassiﬁcation Methods\\nThe goal oftheReClaM module istoprovide machine learning algorithms forsupervised classi-\\nﬁcation andregression inauniﬁed, modular frame work. Itisbuiltlikeaconstruction kit,where\\nthemain building blocks areadapti vedata processing models, error functions, andoptimization\\nc\\r2008Christian Igel,VerenaHeidrich-Meisner andTobiasGlasmachers.', metadata={'source': 'pdfs/igel08a.pdf', 'page': 0}),\n",
       " Document(page_content='IGEL,HEIDRICH-MEISNERANDGLASMACHERS\\n \\nmodel(...)\\nmodelDerivative(...)\\ngeneralDerivative(...)\\ngetParameter(...)\\nsetParameter(...)\\nArray<double>  parameter \\nerror(...)\\nerrorDerivative(...) \\ninit(...)\\noptimize(...)\\n\\x00\\x02\\x01\\x04\\x03\\x06\\x05\\x07\\x05\\t\\x08\\n\\x05\\x07\\x0b\\n\\x0c\\x07\\r\\x0f\\x0e\\x11\\x10\\x0f\\x12\\x11\\x08\\x13\\r\\n\\x14\\x01\\x04\\x15\\x16\\x08\\x06\\x17\\x16\\x18\\x16\\x19 \\x1a\\x1c\\x1b\\n\\x10\\x0f\\x12\\x1e\\x1d\\x1f\\x12\\x11 \\x07\\x18\\n\\x05!#\"!%$\\'&(*)\\n!+\"!%$\\'&\\n!\\x1e,!%$\\'&-\\nFigure 1:Almost allReClaM objects areinherited from one ofthethree base classesModel ,\\nErrorFunction ,andOptimizer .The optimizer hasaccess totheparameter vector w\\nofthemodel f:Rn\\x02Rp!Rm,(x;w)7!fw(x),tominimize ascalar error function E.\\nForgradient-based optimization, theerror function provides thederivativedE=dwbased\\nondf=dw.Inmanycases wecanspeed upthecomputation ofdE=dwbyafactor ofm\\nbyusing aTdf=dw,where aisavector ofcoefﬁcients dependent ontheerror function.\\nalgorithms (see Figure 1).Thesuperclasses representing these components communicate through\\nﬁxedinterf aces. Problem deﬁnition andsolution areclearly separated. Aproblem isdeﬁned bya\\nmodel deﬁning aparametric family ofcandidate hypotheses, andapossibly regularized error func-\\ntiontominimize (and, ofcourse, sample data). Itisusually solvedwith an(iterati ve)optimization\\nalgorithm, which adapts themodel parameters inorder tominimize theerror function evaluated on\\nthegivendata set. Additional error functions anddata setscanthen beused totesttheresulting\\nperformance. This clear structure makesReClaM easy touseandextend.\\nReClaM focuses onkernel methods andneural netw orks. Itoffersavariety ofpredeﬁned net-\\nworkmodels including feed-forw ardandrecurrent multi-layer perceptron netw orks, radial basis\\nfunction netw orks, andCMA Cs.Severalgradient-based optimization algorithms areavailable for\\nnetw orktraining andgeneral purpose optimization including theconjug ategradient method, the\\nBFGS algorithm, andimpro vedRprop (Igel andH¨usken,2003).\\nIntheremainder ofthissection wepresent therealization ofkernel-based learning inmore\\ndetail. The library offerskernelized versions ofseverallearning machines from nearest neighbor\\nclassiﬁers andsimple Gaussian processes todifferent ﬂavorsofsupport vector machines. These\\nalgorithms operate ongeneral kernel objects andusers cansupply newkernel functions easily .At\\nthetime ofwriting, ReClaM provides thefastest support vector machine (SVM) implementation for\\ndense large-scale learning problems. TheSVM training automatically switches between themost\\nefﬁcient SMO-lik ealgorithms available depending onthecurrent problem size (Fanetal.,2005;\\nGlasmachers andIgel, 2006).\\nOntopofthese models, ReClaM deﬁnes meta-models formodel selection ofkernel andregular -\\nization parameters. Itoffersmore objecti vefunctions andoptimization methods formodel selection\\nthan anyother library .Objecti vefunctions include leave-one-out andcross validation errors, radius-\\nmarginquotient, kernel-tar getalignment, andthespan bound (Chapelle etal.,2002; Glasmachers\\nandIgel, 2005; Igel etal.,2007a). Foroptimization, nested grid-search andevolutionary kernel\\nlearning aresupported, andefﬁcient gradient-based optimization isavailable whene verpossible.\\nForboth model training andmodel selection, wemakeuseofReClaM ’ssuperclass architecture to\\ndescribe andsolvetheoptimization problems. Forexample, agradient-based optimization algorithm\\n994', metadata={'source': 'pdfs/igel08a.pdf', 'page': 1}),\n",
       " Document(page_content='SHARK\\nmay decrease aradius-mar ginquotient inorder toadapt thehyperparameters ofanSVM, where in\\neach iteration anSVM model istrained byaspecial quadratic program optimizer todetermine the\\nmargin.\\nToreduce thecomple xity ofSVMs andGaussian processes after training, algorithms forap-\\nproximating thesolutions infeature space areimplemented (Romdhani etal.,2004; Suttorp and\\nIgel, 2007).\\n4.EALib andMOO-EALib—Ev olutionary Single- andMulti-objecti veOptimization\\nTheevolutionary algorithms module (EALib )implements classes forstochastic direct optimization\\nusing evolutionary computing, inparticular genetic algorithms andevolution strate gies(ESs). Evo-\\nlutionary algorithms (EAs) maintain populations (i.e., multi-sets) ofcandidate solutions. Inthe\\nEALib structure, instances oftheclassPopulation contain instances ofIndividual consisting of\\noneormoreChromosome s,which canhavedifferent types. Numerous variation (i.e., mutation and\\nrecombination) operators fordifferent types ofchromosomes, forexample real-v alued orbinary\\nvectors, areavailable. Theuser hasthechoice between manydifferent deterministic andstochastic\\nselection mechanisms operating onpopulation level.\\nThe MOO-EALib extends theEALib toevolutionary multi-objecti ve(i.e., vector valued) opti-\\nmization (EMO). Thegoal ofEMO isusually toapproximate thesetofPareto-optimal solutions,\\nwhere asolution isPareto-optimal ifitcannot beimpro vedinoneobjecti vewithout getting worse\\ninanother one. Toourknowledge, theMOO-EALib module makesSHARK oneofthemost compre-\\nhensi velibraries forEMO. Theefﬁcient implementation ofmeasures forquantifying thequality of\\nsetsofcandidate solutions isastrong argument fortheMOO-EALib .\\nInSHARK weputanemphasis onvariable-metric ESsforreal-v alued optimization. Thus, the\\nmost recent implementation ofthecovariance matrix adaptation ES(CMA-ES; Hansen etal.,2003)\\nanditsEMO counterpart (Igel etal.,2007b) areincluded. WedonotknowanyC++ toolbox for\\nEAs thatcomes close totheEALib interms ofﬂexibility andquality ofalgorithms forcontinuous\\noptimization.\\n5.Availability andRequir ements\\nTheC++ source code isavailable fromhttp://shark- project.sourceforge.net under GNU\\nPublic License andcompiles under MSWindows,Linux, Solaris, andMacOS X.Nothird-party\\nlibraries arerequired, except QtandQwtforgraphical examples.\\nAckno wledgments\\nTheauthors ofthispaper comprise theteam responsible foramajor revision andthemaintenance of\\ntheSHARK library atthetime ofwriting thearticle. The SHARK project wasstarted byM.Kreutz,\\nwho wrote thebasic components such asLinAlg ,Array,andRngaswell astheEALib .Then B.Send-\\nhoffjoined theproject, which wasfused with C.Igel’sReClaM library .Afterw ards, manypeople\\ncontrib uted tothepackage, inparticular (inalphabetic order) R.Alberts, T.B¨ucher ,A.W.Diet-\\nrich, who invented thename Shar k,T.Glasmachers, who extended theReClaM library ,M.H¨usken,\\nT.Okabe, who wrote theMOO-EALib ,S.Roth, P.Stagge, T.Suttorp, M.Toussaint, andT.Voß.The\\nSHARK project issupported bytheHonda Research Institute Europe.\\n995', metadata={'source': 'pdfs/igel08a.pdf', 'page': 2}),\n",
       " Document(page_content='IGEL,HEIDRICH-MEISNERANDGLASMACHERS\\nRefer ences\\nO.Chapelle, V.Vapnik, O.Bousquet, andS.Mukherjee. Choosing multiple parameters forsupport\\nvector machines. Machine Learning ,46(1):131–159, 2002.\\nR.-E. Fan,P.-H.Chen, andC.-J. Lin. Working setselection using thesecond order information for\\ntraining support vector machines. Journal ofMachine Learning Resear ch,6:1889–1918, 2005.\\nT.Glasmachers andC.Igel. Gradient-based adaptation ofgeneral Gaussian kernels. Neur alCom-\\nputation ,17(10):2099–2105, 2005.\\nT.Glasmachers andC.Igel. Maximum-g ainworking setselection forsupport vector machines.\\nJournal ofMachine Learning Resear ch,7:1437–1466, 2006.\\nN.Hansen, S.D.M¨uller,andP.Koumoutsak os.Reducing thetime comple xityofthederandomized\\nevolution strate gywith covariance matrix adaptation (CMA-ES). Evolutionary Computation ,11\\n(1):1–18, 2003.\\nC.IgelandM.H¨usken.Empirical evaluation oftheimpro vedRprop learning algorithm. Neur o-\\ncomputing ,50(C):105–123, 2003.\\nC.Igel, T.Glasmachers, B.Mersch, N.Pfeifer ,andP.Meinick e.Gradient-based optimization of\\nkernel-tar getalignment forsequence kernels applied tobacterial gene start detection. IEEE/A CM\\nTransactions onComputational Biolo gyandBioinformatics ,4(2):216–226, 2007a.\\nC.Igel, N.Hansen, andS.Roth. Covariance matrix adaptation formulti-objecti veoptimization.\\nEvolutionary Computation ,15(1):1–28, 2007b.\\nS.Romdhani, P.Torr,B.Sch¨olkopf,andA.Blak e.Efﬁcient facedetection byacascaded support-\\nvector machine expansion. Proceedings oftheRoyal Society A:Mathematical, Physical and\\nEngineering Sciences ,460(2051):3283–3297, 2004.\\nT.Suttorp andC.Igel. Resilient simpliﬁcation ofkernel classiﬁers. InJ.Marques deS´aetal.,\\neditors, International Confer ence onArtiﬁcial Neur alNetworks (ICANN 2007) ,volume 4668 of\\nLNCS ,pages 139–148. Springer -Verlag, 2007.\\n996', metadata={'source': 'pdfs/igel08a.pdf', 'page': 3}),\n",
       " Document(page_content='Logistic Regression\\nMichael P. LaValley, PhD\\nLike contingency table analyses and /H92732tests, logistic\\nregression allows the analysis of dichotomous or binary\\noutcomes with 2 mutually exclusive levels.1However, logis-\\ntic regression permits the use of continuous or categoricalpredictors and provides the ability to adjust for multiplepredictors. This makes logistic regression especially usefulfor analysis of observational data when adjustment is neededto reduce the potential bias resulting from differences in thegroups being compared.\\n2\\nUse of standard linear regression for a 2-level outcome can\\nproduce very unsatisfactory results. Predicted values for somecovariate values are likely to be either above the upper level(usually 1) or below the lower level of the outcome (usually0). In addition, the validity of linear regression depends onthe variability of the outcome being the same for all values ofthe predictors. This assumption of constant variability doesnot match the behavior of a 2-level outcome. So, linearregression is not adequate for such data, and logistic regres-sion has been developed to fill this gap.\\nSome recent examples of use of logistic regression in\\nCirculation include the assessment of gender as a predictor of\\noperative mortality after coronary artery bypass graftingsurgery,\\n3an evaluation of the relationship between the TaqlB\\ngenotype and risk of cardiovascular disease in a meta-analy-sis,\\n4and an examination of the relationship between lipopro-\\ntein abnormalities and the incidence of diabetes.5\\nThe Logistic Regression Model\\nThe logistic regression model has its basis in the odds of a2-level outcome of interest. For simplicity, I assume that wehave designated one of the outcome levels the event ofinterest and in the following text will simply call it the event.The odds of the event is the ratio of the probability of theevent happening divided by the probability of the event nothappening. Odds often are used for gambling, and “evenodds” (odds /H110051) correspond to the event happening half the\\ntime. This would be the case for rolling an even number on asingle die. The odds for rolling a number /H110215 would be 2\\nbecause rolling a number /H110215 is twice as likely as rolling a 5\\nor 6. Symmetry in the odds is found by taking the reciprocal,\\nand the odds of rolling at leas t a 5 would be 0.5 ( /H110051/2).\\nThe logistic regression model takes the natural logarithm\\nof the odds as a regression function of the predictors. With 1predictor, X, this takes the form ln[odds(Y /H110051)]/H11005\\n/H92520/H11001/H92521X,where ln stands for the natural logarithm, Y is the outcome\\nand Y/H110051 when the event happens (versus Y /H110050 when it does\\nnot),/H92520is the intercept term, and /H92521represents the regression\\ncoefficient, the change in the logarithm of the odds of theevent with a 1-unit change in the predictor X. The differencein the logarithms of 2 values is equal to the logarithm of theratio of the 2 values, so by taking the exponential of\\n/H92521,w e\\nobtain the ratio of the odds (the odds ratio) corresponding toa 1-unit change in X.\\nOdds ratios often are used in the analysis of 2-by-2\\ncontingency tables\\n6and case-control studies.7The odds ratio\\nis sometimes confused with the relative risk, which is theratio of probabilities rather than odds. Only when the prob-ability of the event is very low can the odds ratio beconsidered a good approximation to the relative risk.\\n2The\\nodds ratio is more extreme than the relative risk, which leadsto exaggeration of the effect of a predictor when it ismisinterpreted as a relative risk.\\n8In many settings, the\\nrelative risk is preferred over the odds ratio because it\\naddresses the more readily understood probability of theevent rather than its odds.\\n9However, logistic regression\\nresults are typically presented by odds ratios because theseare the natural estimates from the model and attempts totransform these to relative risks can distort the results.\\n10\\nA useful way to think of the odds ratio is that 100 times the\\nodds ratio minus 1, ie, 100 /H11003(odds ratio /H110021), gives the percent\\nchange in the odds of the event corresponding to a 1-unitincrease in X. If this value is negative, then the odds of theevent decrease with increasing values of X; if positive, theodds increase. This percentage change is the same for any1-unit increase in X because of the assumed linearity betweenX and the logarithm of the odds in the regression modelabove. For some continuous predictors, this assumption maynot match the data,\\n11in which case careful checking of the\\nmodel results is required. For example, if the logarithm of theodds against the predictor X ha s a U shape (both low and high\\nvalues have large odds of the outcome relative to theintermediate values) and the model assumes a linear (straightline) pattern, then goodness-of-fit checking should show thatthe model and the data are not compatible. In such a case,splitting the predictor values into categories and usingdummy variables to code for the categories may improve thefit.\\n1Other methods such as splines also may be used to lessen\\nthe assumption of linearity.12\\nFrom the Department of Biostatistics, Boston University School of Public Health, Boston, Mass.\\nCorrespondence to Dr Michael P. LaValley, Department of Biostatistics, Boston University School of Public Health, 715 Albany St, Crosstown Center\\nRoom 322, Boston, MA 02118. E-mail mlava@bu.edu\\n(Circulation . 2008;117:2395-2399.)\\n© 2008 American Heart Association, Inc.\\nCirculation is available at http://circ.ahajournals.org DOI: 10.1161/CIRCULATIONAHA.106.682658\\n2395Statistical Primer for Cardiovascular Research\\nDownloaded from http://ahajournals.org by on December 11, 2023\\n', metadata={'source': 'pdfs/lavalley-2008-logistic-regression.pdf', 'page': 0}),\n",
       " Document(page_content='When adjusted values are needed, more predictors can be\\nadded to the right side of the regression equation above, alongwith corresponding regression coefficients (\\n/H9252). In this case,\\nthe odds ratio value for X would be adjusted for the otherpredictors in the model. The equation above, 100 /H11003(odds\\nratio/H110021), would then be interpreted as the percent change in\\nthe odds corresponding to a 1-unit increase in X whileholding all other predictors fixed. The selection of appropri-ate predictors to reduce confounding and to improve theprecision of estimates is done similarly for logistic regressionand for linear regression; guidelines can be found in manystatistical textbooks.\\n1,2,12\\nUnlike linear regression, there is no formula for the\\nestimates of /H9252for logistic regression. Finding the best\\nestimates requires repeatedly improving approximate esti-mates until stability is reached. This is done easily on acomputer, and there are many statistical software packagesthat perform logistic regression, but it makes logistic regres-sion less understandable and more of a “black box” approachfor many researchers.\\nAngina in the Framingham Heart Study\\nTo illustrate the use of logistic regression, I use data from theFramingham Heart Study\\n13that are available for teaching\\npurposes from the National Heart, Lung, and Blood Institute(http://www.nhlbi.nih.gov/resources/deca/teaching.htm).These data include subjects at the 1956 Framingham exami-nation, considered to be the baseline, with 24 years offollow-up. Here, I analyze the event of development of newangina pectoris during the follow-up. Subjects with prevalentangina at the 1956 examination are excluded from the data,and only measures from the 1956 examination are used aspredictors. Not all subjects have complete 24-year follow-upbecause some died or left the study before 1980. Use ofsurvival analysis methods to account for varying length offollow-up\\n14would be appropriate for a more definitive study\\nof these data.\\nThe predictor of main interest in my analysis is the\\nmeasure of serum total cholesterol (mg/dL), and I consideradjusting for the sex of the subject, current smoking (yes orno), presence of diabetes (yes or no), age (years), body massindex (kg/m\\n2), and ventricular heart rate (bpm). All of theanalyses were done with SAS version 9.1 (SAS Institute Inc,\\nCary, NC).\\nAfter those with prevalent angina are removed, 4287\\nsubjects remain, and 578 subjects (13.5%) developed newangina during the follow-up. At the 1956 examination, 56.8%of subjects were women, 49.5% were current smokers, and2.9% had diabetes. The mean total cholesterol was 236.7\\nmg/dL (limits, 107 to 696 mg/dL), mean age was 49.6 years(limits, 32 to 70 years), mean body mass index was 25.8kg/m\\n2(limits, 15.5 to 56.8 kg/m2), and mean heart rate was\\n75.9 bpm (limits, 44 to 143 bpm).\\nTable 1 gives the unadjusted and adjusted odds ratios for a\\ndifference of 1 SD (44.622 mg/dL) of cholesterol on the\\noccurrence of new angina during the follow-up. In the unad-\\njusted model, cholesterol is the only predictor; in the adjustedmodel, sex, current smoking, presence of diabetes, age, bodymass index, and heart rate also are included. In the unadjustedmodel, there is a 41.2% increase in the odds of angina witheach 1-SD increase in total cholesterol, and there is a 40.4%increase in the adjusted model. Often, there is greater dis-crepancy between adjusted and unadjusted estimates. So, inthese data, there is little confounding of the effect of choles-terol as a result of the other predictors in the adjusted model.From the adjusted model, the odds of angina are increased42% for men compared with women, and increased bodymass index and decreased heart rate increase the odds ofangina. The effects of current smoking, the presence ofdiabetes, and age are not larger than could be due to chancein these data ( P/H110220.05).\\nIn a data set with fewer cases of angina, the confidence\\ninterval for the adjusted result could be wider owing toincreasing the variability of the estimates when more predic-tors are used than the data would support. A rule of thumb forstability of the estimates from logistic regression is to have atleast 10 events (or nonevents, whichever is rarer in the data)per predictor in the model—more precisely, per degree offreedom used in the model.\\n15Because there are about 83\\ncases of angina for each predictor in the adjusted model, theresults are quite stable.\\nGoodness of Fit\\nOne aspect of the results of logistic regression that is notdescribed in the preceding section is how well the modelTable 1. Unadjusted and Adjusted Odds Ratios for Development of Angina\\nPredictorUnadjusted Adjusted\\nOdds Ratio 95% CI P Odds Ratio 95% CI P\\nCholesterol (1 SD) 1.412 (1.297, 1.537) /H110210.001 1.404 (1.284–1.535) /H110210.001\\nSex 1.415 (1.173–1.705) /H110210.001\\nCurrent smoking 1.035 (0.854–1.255) 0.728Diabetes 1.437 (0.891–2.320) 0.138\\nAge (10 y) 1.088 (0.973–1.216) 0.139\\nBody mass index (1 SD) 1.299 (1.190–1.419) /H110210.001\\nHeart rate (1 SD) 0.867 (0.788–0.953) 0.0031\\nOdds ratios, 95% CIs, and probability values for predictors of angina in the Framingham data. Columns 2 through 4 present results from the\\nunadjusted model; columns 5 through 7 show results from the adjusted model. The respective SDs for cholesterol, body mass index, and heart rateare 44.622 mg/dL, 4.077 kg/m\\n2, and 12.033 bpm.2396 Circulation May 6, 2008\\nDownloaded from http://ahajournals.org by on December 11, 2023\\n', metadata={'source': 'pdfs/lavalley-2008-logistic-regression.pdf', 'page': 1}),\n",
       " Document(page_content='agrees with the observed data. This is called the goodness of\\nfit of the model. The odds ratio values given above describethe model as it is applied to the data. If the model and the dataare not in good agreement, then these odds ratios are not verymeaningful.\\n16Several authors have pointed out that although\\ngoodness of fit is crucial for the assessment of the validity oflogistic regression results in medical research, it often is notincluded in published articles.\\n16–18\\nGoodness of fit is usually evaluated in 2 parts. The first\\nstep is to generate global measures of how well the model fitsthe whole set of observations; the second step is to evaluateindividual observations to see whether any are problematicfor the regression model.\\n1Some global measures of goodness\\nof fit include R2measures for logistic regression; the c\\nstatistic, a measure of how well the model can be used to\\ndiscriminate subjects having the event from subjects nothaving the event; and a test of model calibration developed byHosmer and Lemeshow.\\n19The second part of evaluating\\ngoodness of fit is focused on looking for outliers andinfluence points and may be useful for seeing whetherlinearity in the model is reasonable.\\nTheR\\n2measures for logistic regression mimic the widely\\nused R2measure from linear regression, which gives the\\nfraction of the variability in the outcome that is explained by\\nthe model. However, logistic regression R2does not have\\nsuch intuitive explanation, and values tend to be close to 0\\neven for models that fit well. Because there is an upper boundfor the basic logistic regression R\\n2, a rescaled R2is usually\\nalso presented showing the fraction of the upper bound that is\\nattained. In the logistic regressions predicting angina, themodel containing only cholesterol as a predictor had an R\\n2of\\n0.015 with a rescaled R2of 0.0275. The model containing 7\\npredictors had an R2of 0.0304 and a rescaled R2of 0.0555.\\nThe adjusted model has larger R2values, but it is difficult to\\njudge whether the difference is large enough to be important.\\nThe c statistic measures how well the model can discrim-\\ninate between observations at different levels of the outcome.It is the same as the area under the receiver-operating\\ncharacteristic curve,20formed by taking the predicted values\\nfrom the regression model as a diagnostic test for the event inthe data. The minimum value of c is 0.5; the maximum is 1.0.In their textbook, Hosmer and Lemeshow\\n1consider c values\\nof 0.7 to 0.8 to show acceptable discrimination, values of 0.8to 0.9 to indicate excellent discrimination, and values of /H113500.9\\nto show outstanding discrimination (page 162). The c statisticvalue is 0.603 in the unadjusted model for angina and 0.643in the adjusted model, both below the threshold for acceptablediscrimination.\\nThe Hosmer and Lemeshow test evaluates whether the\\nlogistic regression model is well calibrated so that probabilitypredictions from the model reflect the occurrence of events inthe data. Obtaining a significant result on the test wouldindicate that the model is not well calibrated, so the fit is notgood. For this test, subjects are grouped by their percentile ofpredicted probability of having the event according to themodel: group 1 has subjects with predicted probabilities inthe 1st to 10th percentiles, group 2 has subjects with predictedprobabilities in the 11th to 20th percentiles, and so on. If theobserved and expected numbers of events are very differentin any group, then the model is judged not to fit. Observed\\nand expected values for the groups in the unadjusted andadjusted models for angina are shown in Table 2. Theunadjusted model has a borderline-significant ( P/H110050.094) test\\nresult, indicating possible problems with the model fit. In theadjusted model, the test finds less evidence of lack of fit(P/H110050.854). Inspection of Table 2 shows that the adjusted\\nmodel has much better agreement between observed andexpected numbers of angina events, especially for groupswith low percentages of expected events, ie, in subjects withrelatively low cholesterol.\\nProblematic points are those that are either outliers, data\\nvalues for which the observed value and the model predictionare in poor agreement, or influence points, observations withTable 2. Hosmer and Lemeshow Test Results for Unadjusted and Adjusted Logistic Regression Models\\nPredicted Probability\\nRanking GroupsUnadjusted Model Adjusted Model\\nObserved Angina\\nCases, nExpected Angina\\nCases, nObserved Angina\\nCases, nExpected Angina\\nCases, n\\n1 (Lowest) 26 34.4 22 23.2\\n2 26 40.1 31 31.63 53 43.8 41 38.44 55 49.2 37 44.45 60 52.0 56 50.46 57 57.4 63 56.07 69 61.3 57 62.88 65 65.6 70 71.29 72 75.4 83 83.1\\n10 (Highest) 90 93.8 112 111.1\\n/H9273213.6 4.0\\nP 0.094 0.854\\nHosmer and Lemeshow test results for the prediction of angina in the Framingham data. Columns 2 and 3 show the observed and\\nexpected numbers of angina cases by group for the unadjusted model. Columns 4 and 5 show the observed and expected numbersof angina cases by group for the adjusted model.\\n/H92732Test statistics (on 8 df) and the probability values are shown for each model.LaValley Logistic Regression 2397\\nDownloaded from http://ahajournals.org by on December 11, 2023\\n', metadata={'source': 'pdfs/lavalley-2008-logistic-regression.pdf', 'page': 2}),\n",
       " Document(page_content='an unexpectedly large impact on model results. Checking for\\nproblematic observations is done by plotting residuals againstpredicted values, the model estimate of the probability that asubject will have the event.\\n21Outliers are observations with\\nlarge residuals, and in logistic regression, several residualshave been developed. Here, I use the relatively simplePearson residual, which is the difference between the ob-served and expected outcomes for an observation divided bythe square root of the variability of the expected outcome.Logistic regression residual plots look different from thosefrom linear regression because the residuals fall on 2 curves,1 for each outcome level. Pearson residuals /H110223 and/H11021/H110023\\nwould be considered potential problems, although for largedata sets we should expect some values beyond those limits.There also are several measures of influence for logisticregression. Here, I use the logistic regression version ofCook’s distance, which provides a measure of how much themodel estimates change when each point is removed. Neitheroutliers nor influence points should be discarded automati-cally, but having knowledge of their presence can be used fortargeted data checking and cleaning, or sensitivity analyses.\\nThe Figure is a residual plot for the adjusted model. The\\nhorizontal axis shows the predicted probability of angina foreach observation; the vertical axis shows the Pearson resid-ual. The size of the plotted circle is proportional to the Cook’s\\ndistance for the observation. The higher curve is of subjectswho developed angina, and the lower curve is of subjects whodid not. Because the number of subjects who developedangina is smaller, their observations are generally moreinfluential, and their circles tend to be larger. From theFigure, we can identify several possible problems. First, thereare 2 observations with predicted probabilities of anginabetween 0.75 and 0.80. These come from 2 subjects withunusually high cholesterol values (600 and 696 mg/dL). Thesubject with 696 mg/dL did not develop angina, making arather poor fit to the model and the most influential observa-tion in these data, shown by having the largest circle. Thereare also subjects who developed angina despite having a verylow predicted probability in the model. The low predictedprobabilities for these subjects were primarily due to lowcholesterol values. The mismatch between the observedangina rates and low predicted probability of angina in the\\nregression model for these subjects creates large residuals,and these are the points in the upper left region of the Figure.A substantial number of these subjects have residual values\\n/H110223 and might be considered outliers.\\nSo, although we cannot reject that the adjusted model fits\\nthe data according to the Hosmer and Lemeshow test, the R\\n2\\nand c values are still rather low. In addition, the Figure makes\\nit clear that there are some subjects with low cholesterol whodevelop angina and are not well fit by the model. There arealso some subjects with very high cholesterol who may haveexcessive influence on the model estimates. As a sensitivityanalysis, we might want to remove subjects with cholesterolof/H11350600 mg/dL and see if the model results change substan-\\ntially. We also might consider adding more predictors orallowing a nonlinear effect of cholesterol to see if we canbetter predict angina for subjects with low cholesterol levels.\\nExtensions to the Logistic Regression Model\\nHere, I have considered only outcomes with 2 levels, butthere are extensions to the logistic regression model thatallow analysis of outcomes with /H113503 ordered levels such as no\\npain, moderate pain, or severe pain. Such data often areanalyzed with proportional odds logistic regression,\\n22al-\\nthough other models also are possible.23,24 Multinomial lo-\\ngistic regression may be used if the outcome consists of /H113503\\nunordered categories.1The standard form of logistic regres-\\nsion presented here also presumes that observations areindependent. This would not be the case for longitudinal orclustered data, and analyzing such data as independent couldgive misleading conclusions.\\n25Methods such as generalized\\nestimating equations26or random-effects models27can be\\nused for such data. Finally, survival analysis methods14\\nprovide an extension for studies in which subjects have beenfollowed up for events across extended and varying follow-uptimes.\\nDisclosures\\nNone.\\nReferences\\n1. Hosmer DW, Lemeshow S. Applied Logistic Regression . 2nd ed. New\\nYork, NY: John Wiley & Sons, Inc; 2000.\\nFigure. Residual plot from the adjusted model for\\nangina in the Framingham data. The horizontal axisshows the predicted probability of angina; verticalaxis, the value of the Pearson residual. The size ofthe plotted circle is proportional to the inﬂuence ofan observation.2398 Circulation May 6, 2008\\nDownloaded from http://ahajournals.org by on December 11, 2023\\n', metadata={'source': 'pdfs/lavalley-2008-logistic-regression.pdf', 'page': 3}),\n",
       " Document(page_content='2. Kirkwood BR, Sterne JAC. Essential Medical Statistics . Oxford, UK:\\nBlackwell Science Ltd; 2003.\\n3. Blankstein R, Ward RP, Arnsdorf M, Jones B, Lou YB, Pine M. Female\\ngender is an independent predictor of operative mortality after coronaryartery bypass graft surgery: contemporary analysis of 31 Midwesternhospitals. Circulation . 2005;112(suppl):I-323–I-327.\\n4. Boekholdt SM, Sacks FM, Jukema JW, Shepherd J, Freeman DJ,\\nMcMahon AD, Cambien F, Nicaud V, de Grooth GJ, Talmud PJ,Humphries SE, Miller GJ, Eiriksdottir G, Gudnason V, Kauma H, KakkoS, Savolainen MJ, Arca M, Montali A, Liu S, Lanz HJ, Zwinderman AH,Kuivenhoven JA, Kastelein JJ. Cholesteryl ester transfer protein TaqIBvariant, high-density lipoprotein cholesterol levels, cardiovascular risk,and efficacy of pravastatin treatment: individual patient meta-analysis of13,677 subjects. Circulation . 2005;111:278–287.\\n5. Festa A, Williams K, Hanley AJ, Otvos JD, Goff DC, Wagenknecht LE,\\nHaffner SM. Nuclear magnetic resonance lipoprotein abnormalities inprediabetic subjects in the Insulin Resistance Atherosclerosis Study.Circulation . 2005;111:3465–3472.\\n6. Bland JM, Altman DG. Statistics notes: the odds ratio. BMJ. 2000;\\n320:1468.\\n7. Breslow NE, Day NE. Statistical methods in cancer research, volume I:\\nthe analysis of case-control studies. IARC Sci Publ . 1980:5–338.\\n8. Holcomb WL Jr, Chaiworapongsa T, Luke DA, Burgdorf KD. An odd\\nmeasure of risk: use and misuse of the odds ratio. Obstet Gynecol .\\n2001;98:685–688.\\n9. Davies HT, Crombie IK, Tavakoli M. When can odds ratios mislead?\\nBMJ. 1998;316:989–991.\\n10. McNutt LA, Wu C, Xue X, Hafner JP. Estimating the relative risk in\\ncohort studies and clinical trials of common outcomes. Am J Epidemiol .\\n2003;157:940–943.\\n11. Lee J. An insight on the use of multiple logistic regression analysis to\\nestimate association between risk factor and disease occurrence. Int J\\nEpidemiol . 1986;15:22–29.\\n12. Harrell FE. Regression Modeling Strategies: With Applications to Linear\\nModels, Logistic Regression, and Survival Analysis . New York, NY:\\nSpringer-Verlag; 2001.\\n13. Fox CS, Pencina MJ, Meigs JB, Vasan RS, Levitzky YS, D’Agostino RB\\nSr. Trends in the incidence of type 2 diabetes mellitus from the 1970s tothe 1990s: the Framingham Heart Study. Circulation . 2006;113:2914–\\n2918.14. Hosmer DW, Lemeshow S. Applied Survival Analysis . New York, NY:\\nJohn Wiley & Sons; 1999.\\n15. Peduzzi P, Concato J, Kemper E, Holford TR, Feinstein AR. A simulation\\nstudy of the number of events per variable in logistic regression analysis.J Clin Epidemiol . 1996;49:1373–1379.\\n16. Hosmer DW, Taber S, Lemeshow S. The importance of assessing the fit\\nof logistic regression models: a case study. Am J Public Health . 1991;\\n81:1630–1635.\\n17. Bagley SC, White H, Golomb BA. Logistic regression in the medical\\nliterature: standards for use and reporting, with particular attention to onemedical domain. J Clin Epidemiol . 2001;54:979–985.\\n18. Bender R, Grouven U. Logistic regression models used in medical\\nresearch are poorly presented. BMJ. 1996;313:628.\\n19. Hosmer DW, Lemeshow S. A goodness-of-fit test for the multiple logistic\\nregression model. Commun Stat . 1980;A10:1043–1069.\\n20. Pepe MS. The Statistical Evaluation of Medical Tests for Classification\\nand Prediction . Oxford, UK: Oxford University Press; 2003.\\n21. Friendly M. Visualizing Categorical Data . Cary, NC: SAS Institute Inc;\\n2000.\\n22. Bender R, Grouven U. Ordinal logistic regression in medical research.\\nJ R Coll Physicians Lond . 1997;31:546–551.\\n23. Harrell FE Jr, Margolis PA, Gove S, Mason KE, Mulholland EK,\\nLehmann D, Muhe L, Gatchalian S, Eichenwald HF. Development of aclinical prediction model for an ordinal outcome: the World HealthOrganization Multicentre Study of Clinical Signs and Etiological Agentsof Pneumonia, Sepsis and Meningitis in Young Infants: WHO/ARIYoung Infant Multicentre Study Group. Stat Med . 1998;17:909–944.\\n24. Scott SC, Goldberg MS, Mayo NE. Statistical assessment of ordinal\\noutcomes in comparative studies. J Clin Epidemiol . 1997;50:45–55.\\n25. Cannon MJ, Warner L, Taddei JA, Kleinbaum DG. What can go wrong\\nwhen you assume that correlated data are independent: an illustrationfrom the evaluation of a childhood health intervention in Brazil. Stat Med .\\n2001;20:1461–1467.\\n26. Lipsitz SR, Kim K, Zhao L. Analysis of repeated categorical data using\\ngeneralized estimating equations. Stat Med . 1994;13:1149–1163.\\n27. Twisk JWR. Applied Longitudinal Data Analysis for Epidemiology . Cam-\\nbridge, UK: Cambridge University Press; 2003.\\nKEYWORDS : angina /H18546epidemiology /H18546risk factors /H18546statisticsLaValley Logistic Regression 2399\\nDownloaded from http://ahajournals.org by on December 11, 2023\\n', metadata={'source': 'pdfs/lavalley-2008-logistic-regression.pdf', 'page': 4})]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLITTING TEXT INTO SMALLER CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=text_splitter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/375594560\\nROLDEF: Robust La yered Defense for Intrusion Detection Against Adversarial\\nAttacks\\nConf erence Paper  · Mar ch 2024\\nCITATIONS\\n0READS\\n62\\n3 author s, including:\\nOnat Gung or\\nUniv ersity of Calif ornia, San Die go\\n18 PUBLICA TIONS \\xa0\\xa0\\xa097 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nBaris Aksanli\\nSan Die go St ate Univ ersity\\n83 PUBLICA TIONS \\xa0\\xa0\\xa01,138  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE', metadata={'source': 'pdfs/ROLDEF_DATE24.pdf', 'page': 0})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', '675beaa6-7f0a-4ea9-b74b-b9fcd868705d')\n",
    "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'us-central1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dOWNLOAD EMBEDDINGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE PINECONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone      \n",
    "\n",
    "pinecone.init(      \n",
    "\tapi_key='675beaa6-7f0a-4ea9-b74b-b9fcd868705d',      \n",
    "\tenvironment='gcp-starter'      \n",
    ")      \n",
    "index = pinecone.Index('ritter')\n",
    "\n",
    "index_name ='ritter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch=Pinecone.from_texts([t.page_content for t in docs], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is IIOT?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IIOT stands for Industrial Internet of Things, which refers to the integration of industrial machines and devices with network connectivity, allowing for remote monitoring, data analysis, and automation. It has the potential to improve system efficiency and reliability but also faces security challenges due to increased inter-connectivity and poorly implemented security features, making it an easy target for cybercriminals."
     ]
    },
    {
     "data": {
      "text/plain": [
       "' IIOT stands for Industrial Internet of Things, which refers to the integration of industrial machines and devices with network connectivity, allowing for remote monitoring, data analysis, and automation. It has the potential to improve system efficiency and reliability but also faces security challenges due to increased inter-connectivity and poorly implemented security features, making it an easy target for cybercriminals.'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryStuffs(query):\n",
    "    docs=docsearch.similarity_search(query)\n",
    "    chain=load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    chain.run(input_documents=docs, question=query)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model is based on logistic function, which maps any real-valued probability to a value between 0 and 1. In logistic regression, the relationship between the independent variables (predictors) and the dependent variable (event occurrence) is modeled using a logistic function with a set of parameters. The logistic function takes the form:\n",
      "p(y=1|X) = 1 / (1 + e^(-z))\n",
      "where p(y=1|X) is the probability of the event occurring given the predictor variables X, and z is a linear combination of the predictors. The logistic function has several useful properties that make it an appropriate choice for modeling binary outcomes:\n",
      "* The function is continuous and differentiable everywhere, which makes it easy to work with mathematically.\n",
      "* The function has two discrete values (0 and 1), which corresponds to the two possible outcomes in a binary outcome.\n",
      "* The function can take on any value between 0 and 1, allowing for non-binary outcomes that are closer to one or zero.\n",
      "Overall, logistic regression is based on the logistic function, which allows for modeling of complex relationships between predict"
     ]
    }
   ],
   "source": [
    "query = input(\"What is your question? \")\n",
    "queryStuffs(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
